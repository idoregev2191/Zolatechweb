<!DOCTYPE html>
<html lang="he">
<head>
  <meta charset="UTF-8" />
  <title>Face ID Vision â€“ GitHub Pages Ready v2</title>
  <link rel="icon" href="https://i.postimg.cc/9rnTgGv6/103a204a-164b-4010-9a60-dc4ba2b34d71.png" />
  <style>
    /* (×©××ª×™ ×›××Ÿ ××ª ××•×ª×• ×¢×™×¦×•×‘ VisionOS ××”××™××•×© ×”×§×•×“×) */
    * { margin:0; padding:0; box-sizing:border-box; font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Arial,sans-serif;}
    body{display:flex;align-items:center;justify-content:center;height:100vh;background:linear-gradient(145deg,#ecf1f7,#f9fbff);}
    .glass{backdrop-filter:blur(20px);background:rgba(255,255,255,0.65);border-radius:32px;box-shadow:0 10px 30px rgba(0,0,0,0.1);padding:40px;width:400px;max-width:90vw;text-align:center;animation:fadeIn 1s;}
    @keyframes fadeIn{from{opacity:0;transform:scale(.95);}to{opacity:1;transform:scale(1);}}
    video{width:100%;max-height:300px;border-radius:20px;background:#000;margin:20px 0;object-fit:cover;}
    button{padding:12px 24px;margin:5px;border:none;border-radius:14px;font-weight:600;cursor:pointer;user-select:none;transition:.3s;}
    button:disabled{background:#aac8ff;cursor:not-allowed;}
    #registerBtn{background:#007aff;color:#fff;}
    #registerBtn:hover:not(:disabled){background:#0051c8;}
    #authBtn{background:#34c759;color:#fff;}
    #authBtn:hover:not(:disabled){background:#1a9d48;}
    h1{margin-bottom:10px;font-size:26px;color:#222;}
    #status{margin-top:15px;min-height:24px;font-weight:500;color:#333;}
  </style>
</head>
<body>
  <div class="glass">
    <h1>Face ID Vision v2</h1>
    <video id="video" autoplay muted playsinline></video>
    <div>
      <button id="registerBtn" disabled>ğŸ” ×¨×™×©×•× ×¤× ×™×</button>
      <button id="authBtn" disabled>ğŸ”“ ×–×™×”×•×™ ×¤× ×™×</button>
    </div>
    <p id="status">â³ ×˜×•×¢×Ÿ ××•×“×œ×™×â€¦</p>
  </div>

  <!-- ×˜×¢×Ÿ ××ª face-api.js ××”Ö¾UNPKG ×¢× defer -->
  <script defer src="https://unpkg.com/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <script>
    const video = document.getElementById('video');
    const status = document.getElementById('status');
    const registerBtn = document.getElementById('registerBtn');
    const authBtn = document.getElementById('authBtn');
    let modelsLoaded = false;

    async function loadModels() {
      const MODEL_URL = 'https://justadudewhohacks.github.io/face-api.js/models';
      try {
        console.log('Loading models from', MODEL_URL);
        await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
        await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
        await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);
        console.log('Models loaded');
        status.textContent = "âœ… ××•×“×œ×™× × ×˜×¢× ×•! ××ª×›×•× ×Ÿ ×œ××¦×œ××”â€¦";
        modelsLoaded = true;
        registerBtn.disabled = false;
        authBtn.disabled = false;
      } catch (e) {
        console.error('Error loading models:', e);
        status.textContent = "âŒ ×˜×¢×™× ×ª ××•×“×œ×™× × ×›×©×œ×”: " + e.message;
      }
    }

    async function startVideo() {
      try {
        console.log('Requesting camera access');
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode:"user" } });
        video.srcObject = stream;
        console.log('Camera stream started');
        return true;
      } catch (e) {
        console.error('camera error:', e);
        status.textContent = "âŒ ×’×™×©×” ×œ××¦×œ××” × ×“×—×ª×”. ×‘×“×•×§ ×”×¨×©××•×ª.";
        registerBtn.disabled = true;
        authBtn.disabled = true;
        return false;
      }
    }

    function saveDescriptor(desc) {
      localStorage.setItem('faceDescriptor', JSON.stringify(Array.from(desc)));
      console.log('Descriptor saved');
    }
    function loadDescriptor() {
      const d = localStorage.getItem('faceDescriptor');
      return d ? new Float32Array(JSON.parse(d)) : null;
    }

    async function detectFace() {
      return faceapi
        .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptor();
    }

    async function register() {
      if (!modelsLoaded) return;
      status.textContent = "ğŸ“¸ ×¡×•×¨×§ ×¤× ×™×â€¦";
      const detection = await detectFace();
      if (!detection) {
        status.textContent = "âš ï¸ ×œ× ×–×•×”×• ×¤× ×™×, × ×¡×” ×©×•×‘.";
        return;
      }
      saveDescriptor(detection.descriptor);
      status.textContent = "âœ… ×¤× ×™× × ×¨×©××•!";
    }

    async function authenticate() {
      if (!modelsLoaded) return;
      status.textContent = "ğŸ” ×× ×¡×” ×œ×–×”×•×ªâ€¦";
      const saved = loadDescriptor();
      if (!saved) {
        status.textContent = "âš ï¸ ××™×Ÿ ×¨×™×©×•× ×§×•×“×. ×‘×¦×¢ ×¨×™×©×•× ×¤× ×™×.";
        return;
      }
      const detection = await detectFace();
      if (!detection) {
        status.textContent = "âš ï¸ ×œ× ×–×•×”×• ×¤× ×™×, × ×¡×” ×©×•×‘.";
        return;
      }
      const dist = faceapi.euclideanDistance(detection.descriptor, saved);
      console.log('Distance:', dist);
      status.textContent = dist < 0.45
        ? `âœ”ï¸ ×–×•×”×™×ª! ××¨×—×§: ${dist.toFixed(3)}`
        : `âŒ ×œ× ×ª×•××. ××¨×—×§: ${dist.toFixed(3)}`;
    }

    registerBtn.addEventListener('click', register);
    authBtn.addEventListener('click', authenticate);

    (async () => {
      await loadModels();
      const ok = await startVideo();
      if (ok && modelsLoaded) status.textContent = "ğŸ“¸ ××¦×œ××” ×¤×¢×™×œ×”! ×œ×—×¥ ×¨×™×©×•× ××• ×–×™×”×•×™.";
    })();
  </script>
</body>
</html>
